#!/bin/bash
# ============================================================
# AI Server Install Script
# Debian 12 LXC Container - VLAN 30
# Installerer: NVIDIA drivers, Docker CE, Ollama, Open WebUI
# Kj√∏r som root: bash install-ai-server.sh
# ============================================================

set -e

# ‚îÄ‚îÄ Farger ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log()    { echo -e "${GREEN}[‚úì] $1${NC}"; }
warn()   { echo -e "${YELLOW}[!] $1${NC}"; }
error()  { echo -e "${RED}[‚úó] $1${NC}"; exit 1; }
header() { echo -e "\n${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"; echo -e "${BLUE}  $1${NC}"; echo -e "${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"; }

# ‚îÄ‚îÄ Sjekk root ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if [ "$EUID" -ne 0 ]; then
    error "Kj√∏r scriptet som root: sudo bash $0"
fi

# ‚îÄ‚îÄ Konfigurasjon ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Konfigurasjon"

# Open WebUI port
WEBUI_PORT=3000
# Portainer port
PORTAINER_PORT=9000
# Ollama port
OLLAMA_PORT=11434

echo -e "Open WebUI:  http://$(hostname -I | awk '{print $1}'):${WEBUI_PORT}"
echo -e "Portainer:   http://$(hostname -I | awk '{print $1}'):${PORTAINER_PORT}"
echo -e "Ollama API:  http://$(hostname -I | awk '{print $1}'):${OLLAMA_PORT}"
echo ""
read -p "Fortsett med installasjon? (y/n): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Avbryt."
    exit 0
fi

# ‚îÄ‚îÄ Steg 1: Oppdater system ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 1: Oppdaterer system"
apt-get update -qq
apt-get upgrade -y -qq
apt-get install -y -qq \
    curl wget git nano htop \
    ca-certificates gnupg \
    apt-transport-https \
    software-properties-common \
    lsb-release \
    build-essential \
    pciutils usbutils \
    zstd
log "System oppdatert"

# ‚îÄ‚îÄ Steg 2: NVIDIA driver i LXC ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 2: NVIDIA drivers (LXC modus)"

# I LXC trenger vi bare user-space biblioteker, ikke kernel-moduler
# Kernel-modulene er p√• Proxmox-hosten
if nvidia-smi &>/dev/null; then
    log "NVIDIA GPU funnet og fungerer allerede!"
    nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader
else
    warn "nvidia-smi ikke funnet - installerer NVIDIA user-space pakker"
    
    # Legg til NVIDIA repo
    curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
        gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
    
    curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
    
    apt-get update -qq
    apt-get install -y nvidia-container-toolkit
    
    log "NVIDIA Container Toolkit installert"
fi

# ‚îÄ‚îÄ Steg 3: Docker CE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 3: Installerer Docker CE"

if command -v docker &>/dev/null; then
    warn "Docker er allerede installert: $(docker --version)"
else
    # Fjern gamle versjoner
    apt-get remove -y docker docker-engine docker.io containerd runc 2>/dev/null || true
    
    # Legg til Docker repo
    install -m 0755 -d /etc/apt/keyrings
    curl -fsSL https://download.docker.com/linux/debian/gpg | \
        gpg --dearmor -o /etc/apt/keyrings/docker.gpg
    chmod a+r /etc/apt/keyrings/docker.gpg
    
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
        https://download.docker.com/linux/debian $(lsb_release -cs) stable" | \
        tee /etc/apt/sources.list.d/docker.list
    
    apt-get update -qq
    apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
    
    systemctl enable docker
    systemctl start docker
    log "Docker CE installert: $(docker --version)"
fi

# ‚îÄ‚îÄ Steg 4: Konfigurer Docker med NVIDIA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 4: Konfigurerer Docker + NVIDIA"

nvidia-ctk runtime configure --runtime=docker
systemctl restart docker
log "Docker NVIDIA runtime konfigurert"

# Test GPU i Docker
if docker run --rm --gpus all nvidia/cuda:12.6.0-base-debian12 nvidia-smi &>/dev/null; then
    log "GPU fungerer i Docker!"
else
    warn "GPU test i Docker feilet - sjekk LXC konfig p√• Proxmox"
fi

# ‚îÄ‚îÄ Steg 5: Portainer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 5: Installerer Portainer CE"

if docker ps -a --format '{{.Names}}' | grep -q "^portainer$"; then
    warn "Portainer kj√∏rer allerede"
else
    docker volume create portainer_data
    docker run -d \
        -p ${PORTAINER_PORT}:9000 \
        --name portainer \
        --restart always \
        -v /var/run/docker.sock:/var/run/docker.sock \
        -v portainer_data:/data \
        portainer/portainer-ce:latest
    log "Portainer installert p√• port ${PORTAINER_PORT}"
fi

# ‚îÄ‚îÄ Steg 6: Ollama ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 6: Installerer Ollama"

if command -v ollama &>/dev/null; then
    warn "Ollama er allerede installert: $(ollama --version)"
else
    curl -fsSL https://ollama.com/install.sh | sh
    log "Ollama installert"
fi

# Konfigurer Ollama til √• lytte p√• alle grensesnitt
mkdir -p /etc/systemd/system/ollama.service.d
cat > /etc/systemd/system/ollama.service.d/override.conf << 'EOF'
[Service]
Environment="OLLAMA_HOST=0.0.0.0"
Environment="OLLAMA_ORIGINS=*"
EOF

systemctl daemon-reload
systemctl enable ollama
systemctl restart ollama
sleep 3

if systemctl is-active --quiet ollama; then
    log "Ollama kj√∏rer og lytter p√• 0.0.0.0:${OLLAMA_PORT}"
else
    error "Ollama startet ikke - sjekk: journalctl -u ollama"
fi

# ‚îÄ‚îÄ Steg 7: Last ned anbefalte modeller ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 7: Laster ned AI-modeller"

echo "Med 48GB VRAM (2xA2 + T4) kan du kj√∏re store modeller!"
echo ""
echo "Velg hvilke modeller du vil installere:"
echo "1) Basis pakke    - mistral:7b + llama3.1:8b (rask, ~10GB)"
echo "2) Kraftig pakke  - qwen2.5:32b + deepseek-r1:32b (~40GB)"
echo "3) Maks pakke     - llama3.3:70b + qwen2.5:72b (~80GB, bruker litt swap)"
echo "4) Ingen          - installer manuelt senere"
echo ""
read -p "Velg (1-4): " model_choice

case $model_choice in
    1)
        log "Laster ned basis pakke..."
        ollama pull mistral:latest
        ollama pull llama3.1:8b
        ;;
    2)
        log "Laster ned kraftig pakke (tar litt tid)..."
        ollama pull qwen2.5:32b
        ollama pull deepseek-r1:32b
        ;;
    3)
        log "Laster ned maks pakke (tar lang tid)..."
        ollama pull llama3.3:70b
        ollama pull qwen2.5:72b
        ;;
    4)
        warn "Hopper over modeller - last ned manuelt med: ollama pull <modell>"
        ;;
    *)
        warn "Ugyldig valg - hopper over"
        ;;
esac

# ‚îÄ‚îÄ Steg 8: Open WebUI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 8: Installerer Open WebUI"

HOST_IP=$(hostname -I | awk '{print $1}')

if docker ps -a --format '{{.Names}}' | grep -q "^open-webui$"; then
    warn "Open WebUI kj√∏rer allerede - restarter med riktig konfig"
    docker stop open-webui
    docker rm open-webui
fi

docker run -d \
    -p ${WEBUI_PORT}:8080 \
    -e OLLAMA_BASE_URL=http://${HOST_IP}:${OLLAMA_PORT} \
    -e WEBUI_SECRET_KEY=$(openssl rand -hex 32) \
    -v open-webui:/app/backend/data \
    --name open-webui \
    --restart always \
    ghcr.io/open-webui/open-webui:main

sleep 5

if docker ps --format '{{.Names}}' | grep -q "^open-webui$"; then
    log "Open WebUI installert og kj√∏rer!"
else
    error "Open WebUI startet ikke - sjekk: docker logs open-webui"
fi

# ‚îÄ‚îÄ Steg 9: Brannmur (valgfritt) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "Steg 9: Nettverksinfo VLAN 30"

echo -e "${YELLOW}Husk √• √•pne disse portene i UniFi/brannmur for VLAN 30:${NC}"
echo "  Port 3000  - Open WebUI"
echo "  Port 9000  - Portainer"
echo "  Port 11434 - Ollama API"

# ‚îÄ‚îÄ Ferdig ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
header "üéâ Installasjon fullf√∏rt!"

HOST_IP=$(hostname -I | awk '{print $1}')

echo -e "${GREEN}"
echo "  ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
echo "  ‚ïë           TILGANG TIL TJENESTER            ‚ïë"
echo "  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£"
echo "  ‚ïë  Open WebUI:  http://${HOST_IP}:${WEBUI_PORT}          ‚ïë"
echo "  ‚ïë  Portainer:   http://${HOST_IP}:${PORTAINER_PORT}          ‚ïë"
echo "  ‚ïë  Ollama API:  http://${HOST_IP}:${OLLAMA_PORT}        ‚ïë"
echo "  ‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£"
echo "  ‚ïë  Last ned modeller:                        ‚ïë"
echo "  ‚ïë  ollama pull qwen2.5:32b                   ‚ïë"
echo "  ‚ïë  ollama pull deepseek-r1:70b               ‚ïë"
echo "  ‚ïë  ollama pull llama3.3:70b                  ‚ïë"
echo "  ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
echo -e "${NC}"

# Sjekk GPU status
echo -e "\n${BLUE}GPU Status:${NC}"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader 2>/dev/null || \
    warn "nvidia-smi ikke tilgjengelig - sjekk GPU passthrough i Proxmox"

echo -e "\n${BLUE}Kj√∏rende containere:${NC}"
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
